# ゼロから作るディープラーニング１

2023/2/9　1章, 2章　完  
2023/2/10　3章　完  
バッチ処理について:  機械学習ライブラリは大きな配列の計算を効率よくできるように最適化されている。  なので、損失関数の計算は一つ一つのデータの組み(正解ラベルとNNの出力)に対して実行するより、データをある程度まとめて、いっきに実行する方が効率がいい。  
2023/2/11 4章  
2023/2/12 4章　完  
復習:   class実装の流れ、学習の流れ  行列計算の可視化をしたい  バッチ処理のためのデータ処理(行列管理)  
勾配の計算は完璧  
☆復習ちゃんとやる!  
class 内で def __init__とするとコンストラクタを生成できる。  
class TwoLayerNet (__init__, predict(sigmoid, softmax), loss(cross_entropy_error), accuracy, gradient)  
何がわからないのかわからなくなった。  

静的メソッドなるものと遭遇。  
静的メソッドはオブジェクトを生成しなくても実行できるらしい。使い道あるの？  
-----  
静的メソッド (または 静的関数) とは、メソッドのうちオブジェクトのメンバーとして定義されているものの、コンストラクターで生成されたオブジェクトインスタンスからではなく、API のオブジェクトコンストラクターから直接アクセスできるものです。

なお， @staticmethod のデコレータを用いて，静的メソッドとして定義してあります． sigmoid() は数学関数であり，値はその引数だけに依存し，オブジェクトやクラスの内容や状態には依存しないので，このように静的メソッドとして定義しました．  
-----  

逆にいえば、オブジェクトやクラスの内容状態に依存するような関数をまとめたのがクラスってこと？

2023/2/13  
活性化関数の意義:  非線形な変換器を利用することで複雑な非線形表現を学習できる。  
逆に活性化関数がなければ、線形表現しか学習できずDNN自体が線形な写像になってしまう。  
